import tensorflow as tf
import numpy as np
import tensorflow_addons as tfa
eps = 1e-6

class Encoder(tf.keras.Model):

    def __init__(self, kernel_size, out_channels=256):
        super(Encoder, self).__init__()
        self.conv = tf.keras.layers.Conv1D(kernel_size=kernel_size, filters=out_channels, use_bias=False,
                                           strides=kernel_size//2, padding="same")

    def call(self, inputs, training=None, mask=None):
        """
        input_shape = [Bs, samplepts, chs~1 or not]
        """
        inputs = tf.nn.relu(self.conv(inputs))
        return inputs


class Decoder(tf.keras.Model):
    def __init__(self, kernel_size=2):
        super(Decoder, self).__init__()
        self.conv = tf.keras.layers.Conv1DTranspose(kernel_size=kernel_size, filters=1, use_bias=False,
                                                    strides=kernel_size//2, padding="same")

    def call(self, inputs, training=None, mask=None):
        """
        input_shape = [Bs, samplepts//stride, channels]
        output_shape = [Bs, samplepts, spk]
        """
        inputs = self.conv(inputs)
        return tf.squeeze(inputs)


def segmentation(x, k):
    bs, length, chs = x.get_shape().as_list()
    p = k // 2
    gap = k - (p + length) % k

    x = tf.pad(x, ((0, 0), (0+p, gap+p), (0, 0)))
    x_leading = x[:, :-p, :]
    x_leading = tf.reshape(x_leading, [bs, -1, k, chs])
    x_lagging = x[:, p:, :]
    x_lagging = tf.reshape(x_lagging, [bs, -1, k, chs])
    concate = tf.concat([x_leading, x_lagging], axis=-2)
    concate = tf.reshape(concate, [bs, -1, k, chs])
    return concate, gap


def over_add(x, pad_len):
    bs, n, k, hidden = x.shape
    x = tf.transpose(x, [0, 3, 1, 2])
    x = tf.reshape(x, [bs*hidden, n, k])
    x = tf.signal.overlap_and_add(x, frame_step=k//2)
    x = x[:, k//2:-(pad_len+k//2)]
    x = tf.reshape(x, [bs, hidden, -1])
    x = tf.transpose(x, [0, 2, 1])
    return x


class DPRNNblock(tf.keras.Model):
    def __init__(self,
                 feature_channels,
                 hidden_channels):
        super(DPRNNblock, self).__init__()
        self.intra_rnn = tf.keras.layers.Bidirectional(
            tf.keras.layers.LSTM(units=hidden_channels, return_sequences=True))
        self.inter_rnn = tf.keras.layers.Bidirectional(
            tf.keras.layers.LSTM(units=hidden_channels, return_sequences=True))
        self.intra_norm = tfa.layers.GroupNormalization()
        self.inter_norm = tfa.layers.GroupNormalization()
        self.intra_linear = tf.keras.layers.Conv1D(filters=feature_channels, kernel_size=1, use_bias=False)
        self.inter_linear = tf.keras.layers.Conv1D(filters=feature_channels, kernel_size=1, use_bias=False)

    def call(self, inputs, training=None, mask=None):
        """
        input_shape = [Bs, N, K, chs]
        eq shape mapping
        """
        output = inputs
        Bs, N, K, chs = inputs.get_shape().as_list()
        inputs = tf.reshape(inputs, [Bs*N, K, chs])
        inputs = self.intra_rnn(inputs)
        inputs = self.intra_linear(inputs)
        inputs = tf.reshape(inputs, [Bs, N, K, chs])
        inputs = self.intra_norm(inputs)
        output += inputs

        inputs = tf.reshape(tf.transpose(output, [0, 2, 1, 3]), [Bs*K, N, chs])
        inputs = self.inter_rnn(inputs)
        inputs = self.inter_linear(inputs)
        inputs = tf.transpose(tf.reshape(inputs, [Bs, K, N, chs]), [0, 2, 1, 3])
        inputs = self.inter_norm(inputs)
        output += inputs
        return output


class Auxgateoutput(tf.keras.Model):
    """
    Aux gate output for DPRNN
    https://github.com/ShiZiqiang/dual-path-RNNs-DPRNNs-based-speech-separation/blob/master/models.py
    """
    def __init__(self, input_channels, target_channels):
        super(Auxgateoutput, self).__init__()
        self.out = tf.keras.layers.Conv1D(input_channels, kernel_size=1)
        self.gate = tf.keras.layers.Conv1D(input_channels, kernel_size=1, kernel_initializer=tf.keras.initializers.Zeros(),
                                           bias_initializer=tf.keras.initializers.Constant(1.))
        self.maskconv1x1 = tf.keras.layers.Conv1D(target_channels, kernel_size=1, use_bias=True)

    def call(self, inputs, training=None, mask=None):
        inputs = self.maskconv1x1(inputs)
        return tf.nn.tanh(self.out(inputs)) * tf.nn.sigmoid(self.gate(inputs))


class DPRNN(tf.keras.Model):
    """
    basic_model of DPRNN
    """
    def __init__(self, feature_channels, hidden_channels,
                 num_layers=6,
                 K=200):
        super(DPRNN, self).__init__()
        self.K = K
        self.norm = tfa.layers.GroupNormalization()
        self.dense2hidden = tf.keras.layers.Conv1D(filters=feature_channels,
                                                   kernel_size=1,
                                                   use_bias=True)
        self.dual_rnn = tf.keras.Sequential([])
        for i in range(num_layers):
            self.dual_rnn.add(DPRNNblock(hidden_channels=hidden_channels, feature_channels=feature_channels))

    def call(self, inputs, training=None, mask=None):
        inputs = self.norm(inputs)
        inputs = self.dense2hidden(inputs)
        inputs, pad_len = segmentation(inputs, self.K)
        # [Bs, N, K, chs]
        inputs = self.dual_rnn(inputs)
        inputs = over_add(inputs, pad_len)
        return inputs


class Model(tf.keras.Model):
    def __init__(self,
                 enc_channels,
                 feature_channels,
                 hidden_channels,
                 kernel_size=2,
                 num_layers=6,
                 K=200):
        super(Model, self).__init__()
        self.enc = Encoder(kernel_size=kernel_size, out_channels=enc_channels)
        self.dec = Decoder(kernel_size=kernel_size)
        self.sepration = DPRNN(feature_channels,
                               hidden_channels,
                               num_layers,
                               K)
        self.compressgate = Auxgateoutput(input_channels=enc_channels, target_channels=enc_channels)

    def call(self, inputs, training=None, mask=None):
        e = self.enc(inputs[..., tf.newaxis])
        s = self.sepration(e)
        s = tf.nn.relu(self.compressgate(s))
        audios = self.dec(s*e)
        return audios


if __name__ == '__main__':
    test_inputs = np.random.normal(size=[2, 16384])
    test_inputs = tf.cast(test_inputs, tf.float32)
    Model_basic = Model(enc_channels=256, feature_channels=64, hidden_channels=128, K=180)
    data = Model_basic(test_inputs)
    print(data.shape)
    Model_basic.summary()
